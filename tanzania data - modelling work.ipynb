{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use paired with data production notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T17:00:28.396867Z",
     "start_time": "2020-07-29T17:00:28.267884Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import urllib.request\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector\n",
    "## ANCHORUP\n",
    "log_transformer=FunctionTransformer(func=np.log,inverse_func=np.exp,validate=False,check_inverse=False)\n",
    "#validate has to be false for the nans to work, as does check_inverse\n",
    "#Currently not being used\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from IPython.display import Audio\n",
    "def announce_when_done(target_file='https://www.myinstants.com/media/sounds/meme-de-creditos-finales.mp3'):\n",
    "    '''\n",
    "    place at the end of a notebook, this will play a file when done.  I have no idea how it adds to \n",
    "    notebook memory overhead.  Hopefully not much.\n",
    "    '''\n",
    "    return Audio(url=target_file,autoplay=True)\n",
    "import missingno as msno\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T16:34:20.472478Z",
     "start_time": "2020-07-29T16:34:20.041969Z"
    }
   },
   "outputs": [],
   "source": [
    "wwdf=pd.read_csv('cleaned_data_072920_shaw.csv')\n",
    "\n",
    "try:\n",
    "    wwdf.set_index('id',inplace=True)\n",
    "except:\n",
    "    print('index probably already set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T17:07:55.657743Z",
     "start_time": "2020-07-29T17:07:55.390289Z"
    }
   },
   "outputs": [],
   "source": [
    "memo=[]\n",
    "#Quality of life features\n",
    "\n",
    "# Mostly ordered in terms of apparent quality, except for location\n",
    "# columns that seem to be about roughly the same thing\n",
    "# treating long&lat&elevation separate from other location stuff for syntactical reasons\n",
    "# similarly, water_quality_character&water_quality_abandoned are not in here as they should be used together\n",
    "exclusives=[['basin','subvillage','region','region_code','district_code','lga','ward'],\n",
    " ['scheme_management','scheme_name'],\n",
    " ['extraction_type_group','extraction_type_class','extraction_type'],\n",
    " ['management','management_group'],\n",
    " ['payment_type','payment'],\n",
    " ['water_quality','quality_group'],\n",
    " ['quantity','quantity_group'],\n",
    " ['source_class','source','source_type'],\n",
    " ['waterpoint_type','waterpoint_type_group']\n",
    "]\n",
    "\n",
    "be_wary=['population','installer','subvillage','lga']\n",
    "\n",
    "lage_sets=[c for c in wwdf.select_dtypes(exclude='number').columns if wwdf[c].nunique()>=100]\n",
    "\n",
    "notes=['water_quality_character&water_quality_abandoned not in exc','lat&long&elev not in exc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T16:31:21.876450Z",
     "start_time": "2020-07-29T16:31:21.444577Z"
    }
   },
   "source": [
    "# The column transforming function I'll be using a good bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T16:36:36.905427Z",
     "start_time": "2020-07-29T16:36:36.898704Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_cts(df,scaler,fill_value_input='none',fill_value_strategy='constant'):\n",
    "    '''\n",
    "    takes in df, scaler, fill_value_input,fill_value_strategy\n",
    "    outputs transformers to handle imputing categorical variables and onehotencoding & doing specified numerical scaling.\n",
    "    \n",
    "    All data should be string or numeric. Output will be two transformeres, which will appropriately handle mixed data:\n",
    "    \n",
    "    imputer_transformer,encode&scale_transformer.\n",
    "    \n",
    "    Passing multiple scalers might work???? Why would you even do that though.  But it probably would.  But only if you're\n",
    "    applying it to everything.  Otherwise, pass another column transformer after the fact and uh good luck with that lmao.\n",
    "    \n",
    "    the kw definitions are open and obvious, but be careful as some of the safeguards are gone.\n",
    "    OneHotEncoder is fixed with unknown_values='ignore'\n",
    "    '''\n",
    "    print(\"if  you forgot to set up an assignment or save you should probably hit interrupt and do that now\")\n",
    "    number_cols_initial=[df.columns.get_loc(c) for c in df.select_dtypes(include='number')]\n",
    "    cat_cols_initial=[df.columns.get_loc(c) for c in df.select_dtypes(exclude='number')]\n",
    "    \n",
    "    ctoheimp=ColumnTransformer([('impute',SimpleImputer(strategy=fill_value_strategy,\n",
    "                                                        fill_value=fill_value_input),cat_cols_initial)]\n",
    "                               ,remainder='passthrough')\n",
    "    \n",
    "    \n",
    "    ctohe2=ColumnTransformer([('OHE',OneHotEncoder(handle_unknown='ignore',sparse=False),slice(0,len(cat_cols_initial))),\n",
    "                              ('rescale num2',scaler,slice(len(cat_cols_initial),\n",
    "                                                                                      df.shape[1]))],\n",
    "                             remainder='passthrough')     \n",
    "    #It'd be nice to figure out a cleaner way to handle sparse arrays\n",
    "    return ctoheimp,ctohe2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting with just some collection of features:\n",
    "(still would like a way to do a faster/better imputing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T17:00:41.403429Z",
     "start_time": "2020-07-29T17:00:41.325450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if  you forgot to set up an assignment or save you should probably hit interrupt and do that now\n"
     ]
    }
   ],
   "source": [
    "X=wwdf.copy()[['basin','extraction_type','latitude','longitude','payment_type','water_quality_character','water_quality_abandoned']]\n",
    "y=wwdf.copy()['status_group']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.2,random_state=60120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a DCT model:\n",
    "(need to adjust how it's scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T17:09:11.335144Z",
     "start_time": "2020-07-29T17:09:02.277708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if  you forgot to set up an assignment or save you should probably hit interrupt and do that now\n",
      "[0.69833754 0.69886364 0.68939394 0.69896886 0.69633838]\n",
      "mean score: 0.6963804713804713\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"https://www.myinstants.com/media/sounds/meme-de-creditos-finales.mp3\" type=\"audio/mpeg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp,enc=prepare_cts(X_train,MinMaxScaler())\n",
    "\n",
    "pipeline=Pipeline([('impute categorical',imp),('encode&scale',enc),('KNN impute',KNNImputer()),('DCT',DecisionTreeClassifier(random_state=60120))])\n",
    "\n",
    "scores=cross_val_score(pipeline,X_train,y_train)\n",
    "\n",
    "print(scores)\n",
    "print('mean score:',scores.mean())\n",
    "\n",
    "memo.append(\n",
    "    \n",
    "    {'name':'Vanilla DCT','model':DecisionTreeClassifier(random_state=60120),\n",
    "     'model_params':pipeline['DCT'].get_params(),\n",
    "     'full_params':pipeline.get_params(),\n",
    "    'features':X_train.columns,\n",
    "    'scores':scores,\n",
    "    'mean_scores':scores.mean()}\n",
    "           )\n",
    "\n",
    "announce_when_done()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T16:57:12.776369Z",
     "start_time": "2020-07-29T16:57:12.769556Z"
    }
   },
   "source": [
    "## Using a vanilla XGB, still with not-great scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-29T17:09:08.966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if  you forgot to set up an assignment or save you should probably hit interrupt and do that now\n"
     ]
    }
   ],
   "source": [
    "imp,enc=prepare_cts(X_train,MinMaxScaler())\n",
    "\n",
    "pipeline=Pipeline([('impute categorical',imp),('encode&scale',enc),('KNN impute',KNNImputer()),('fxn',\n",
    "                                                                                               XGBClassifier()\n",
    "                                                                                               )])\n",
    "\n",
    "scores=cross_val_score(pipeline,X_train,y_train)\n",
    "\n",
    "print(scores)\n",
    "print('mean score:',scores.mean())\n",
    "\n",
    "memo.append(\n",
    "    \n",
    "    {'name':'Vanilla XGB','model':pipeline['fxn'],\n",
    "     'model_params':pipeline['fxn'].get_params(),\n",
    "     'full_params':pipeline.get_params(),\n",
    "    'features':X_train}\n",
    "           )\n",
    "\n",
    "announce_when_done()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
